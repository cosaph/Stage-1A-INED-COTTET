---
title: "Générer des graphes de mot à partir d'un texte avec R.temis"
toc-title: ""
categories:
- R
- R-Studio
author: "COTTET Coralie"
affiliations: INED

date: 06/06/2023

---



Nous allons réaliser un nuage de mot et un graphe de mot.


Les packages "R.temis", "dplyr" et "tibble" sont nécessaires pour ce code car ils contiennent des fonctions et des outils qui sont utilisés pour manipuler et analyser les données textuelles.

Le package "R.temis" fournit des fonctions pour les traitements de statistique textuelle (création d'un tableau lexical et calcul d'occurence des mots).

Le package "dplyr" fournit des fonctions pour la manipulation de données, telles que la sélection de colonnes, le filtrage de données et l'agrégation de données. Ces fonctions sont utilisées dans le code pour nettoyer et préparer les données textuelles.

Le package "tibble" fournit une classe de données pour stocker des données tabulaires, qui est plus efficace que la classe de données par défaut de R. Cette classe de données est utilisée dans le code pour stocker les données textuelles nettoyées et préparées.




```{r warning=FALSE, message= FALSE}
# Appel des packages (à installer si besoin)
library("R.temis")
library("dplyr") #Pour le traitement du texte voir la fiche "Faciliter la manipulation de données avec Dplyr".
library("tibble")
```


Concernant le choix des données, j’ai choisis les voeux de François Hollande allant de 2013 à 2017. Les textes retranscrits dans des fichiers de type texte (.txt) et placé dans un seul dossier nommé _dossier_de_texte_. 

```{r message=FALSE }

# import des textes avec la fonction import_corpus

corpus1 <- import_corpus("dossier_de_texte", format="txt", language ="fr")

# découpage en unités textuelles de 5 paragraphes pour un meilleur rendu 

corpus<-split_documents(corpus1, 5, preserveMetadata = TRUE)


```





Les stop words (ou mots vides) sont des mots très courants d’une langue comme les prépositions, les articles, les pronoms, etc., qui sont souvent omis lors de l’analyse car en général ils ne portent pas de sens important pour la compréhension globale du texte.
La fonction _'build_dtm'_ est utilisée pour construire une matrice de termes-document (ou tableau lexical) à partir d’un corpus de textes. La matrice de termes-document (ou Tableau Lexical) est une représentation quantitative d'un corpus de textes, où chaque colonne représente un terme et chaque ligne représente un document. Ici les documents sont les unités textuelles (composées de 5) paragraphes.

On choisit de supprimer les mots vides.

On passe maintenant à la création du tableau lexical (dtm) sans mots outils et avec les mots d’au moins 1 lettre.


```{r}
#on crée le tableau lexical avec la fonction build_dtm

dtm <-build_dtm(corpus, remove_stopwords = T, min_length = 1)

# Calcul des occurrences des mots dans le corpus de textes

frequent_terms(dtm) 

```
Le mot "france" est prononcé 66 fois dans l'ensemble des 5 discours et représente 1,95% des occurences totales.


On va maintenant affiner l'analyse

J’aimerais aussi retirer les mots “a” et “plus” et rassembler sous un même mot  les termes “tout”, “toutes” et “tous” en “tous.tes” à titre d’exemple.

On crée le dictionnaire qui affiche les mots initiaux et les racines des mots (Term). Il va servir à lemmatiser le corpus.

lemmatiser c'est remplacer les mots initiaux par des termes: la racine des mots ou une forme personnalisée (comme c'est le cas ici)

```{r}

# Création d'un dictionnaire de mot
dic <-dictionary(dtm) 

dic2 = dic %>%
  rownames_to_column(var="word") %>% 
  mutate(Term = word)

row.names(dic2) <- dic2$word

# Remplacer les mots spécifiés par tous.tes
dic2$Term[dic2$word == "toutes"] <- "tous.tes"
dic2$Term[dic2$word == "tout"] <- "tous.tes"
dic2$Term[dic2$word == "tous"] <- "tous.tes"

# Lemmatisation
dtmlem <-combine_terms(dtm, dic2)

# Ensemble de mots à retirer
mots_a_retirer <- c("a", "plus")

# Suppression de mots dans le tableau lexical
dtm2<-dtmlem[, !colnames(dtmlem) %in% mots_a_retirer]


frequent_terms(dtm2)
```
On voit que les occurences du "tous.tes" (64) correspondent bien à la somme des occurences de tout (24), tous(24) et toutes(16).


On passe à l'affichage du Nuage de mot

Ce graphique permet de visualiser les mots les plus __occurents__ d’un corpus de textes 
```{r}

# On affiche au maximum 50 mots et les mots d’au moins une occurrence
cloud<-word_cloud(dtm2, color= 'black', min.freq=1,n =50) 
title(main = "Mots les plus fréquents dans les discours de Hollande entre 2013 et 2017")

```


La taille de la police est proportionelle à l'occurence du "mot".
France (66), année (33) et entreprise (11).


Et pour finir, l'affichage d’un graphe de mots

La fonction _'terms_graph'_ du package R.temis permet de générer un réseau de mots qui est affiché dans une fenêtre interactive igraph. Les termes ou mots sont représentés par des sommets (ou nœuds) du graphe, les liens représentent les __cooccurrences__ entre les mots les plus fréquents. Leur placement dans l’espace graphique est déterminé par un algorithme d’énergie. 

```{r}
# Créer un graphique d'analyse de co-occurrences de termes

Tree<-terms_graph(dtm2, min_occ = 10, interactive = T,
            vertex.size = 0.01, vertex.color = "lightblue",
            label.cex = 0.1)


```

<img src="tree.PNG" alt="Texte alternatif de l'image" title="Titre de l'image" width=500 lenght=500/>



# 7. Pour aller plus loin

<https://rtemis.hypotheses.org/r-temis-dans-rstudio>










































